{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Latent dim is the number of means there are. Note that number of means = number of variance\n",
    "\n",
    "    Keep hidden_dims as a list so in the vae model we can pass the same hidden_dims into both the encoder and decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=4096, hidden_dims=[32, 64, 128, 256, 512], latent_dim=256) -> None:\n",
    "        super().__init__()\n",
    "        kernel_size=5\n",
    "        stride=2\n",
    "        padding=1\n",
    "\n",
    "        conv_to_fc_mult = 3\n",
    "        latent_dim_mult = 3\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        for i in range(len(hidden_dims)):\n",
    "            out_dim = hidden_dims[i]\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_dim,\n",
    "                          out_channels=out_dim,\n",
    "                          kernel_size=kernel_size, \n",
    "                          stride=stride, \n",
    "                          padding=padding),\n",
    "                nn.BatchNorm2d(out_dim),\n",
    "                nn.LeakyReLU()\n",
    "            )\n",
    "            modules.append(layer)\n",
    "            in_dim = out_dim\n",
    "    \n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        # We might need to find a way to force the gaussians to have a mean of 0\n",
    "        # and a std of 1\n",
    "        self.fc_mu = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1]*conv_to_fc_mult, latent_dim)\n",
    "        )\n",
    "\n",
    "        self.fc_var = nn.Sequential(\n",
    "            nn.Linear(hidden_dims[-1]*conv_to_fc_mult, latent_dim)\n",
    "        )\n",
    "    \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
