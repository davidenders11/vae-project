{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import os\n",
    "import matplotlib.image as img\n",
    "import tqdm\n",
    "from vae import Basic_VAE\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "cats = []\n",
    "directory = \"data/cats\"\n",
    "count = 0\n",
    "for catpic in os.listdir(directory):\n",
    "    if count < 1000:\n",
    "        # read from image and convert to tensor\n",
    "        im = torch.tensor(img.imread(os.path.join(directory, catpic))).float()\n",
    "        # permute to (channels, height, width) for conv2d layer\n",
    "        im = torch.permute(im, (2, 0, 1))\n",
    "        # normalize to range between -1 and 1\n",
    "        im = im / 128 - 1\n",
    "        cats.append(im)\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "cats = torch.stack(cats)\n",
    "print(cats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Training/Validation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 64, 64])\n",
      "torch.Size([2, 3, 64, 64])\n",
      "torch.Size([2, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Split the data into what we use for testing and not testing\n",
    "training_test_split = 0.75\n",
    "training_test_cutoff = int(cats.shape[0] * training_test_split + 1)\n",
    "random_perm = torch.randperm(cats.shape[0])\n",
    "not_test_tensor = cats[:training_test_cutoff]\n",
    "testing_tensor = cats[training_test_cutoff:]\n",
    "# Split the data into what we use for training and cross validation\n",
    "training_cv_split = 0.8\n",
    "training_cv_cutoff = int(not_test_tensor.shape[0] * training_cv_split)\n",
    "training_tensor = not_test_tensor[:training_cv_cutoff]\n",
    "cv_tensor = not_test_tensor[training_cv_cutoff:]\n",
    "print(training_tensor.shape)\n",
    "print(cv_tensor.shape)\n",
    "print(testing_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose Hyperparameters and Build Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 64, 32, 16]\n",
      "[128, 64, 32, 16]\n"
     ]
    }
   ],
   "source": [
    "from vae import Basic_VAE\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "\n",
    "hidden_dims = [16, 32, 64, 128]\n",
    "latent_dim = 64\n",
    "in_dim = 3\n",
    "model = Basic_VAE(in_dim, hidden_dims, latent_dim)\n",
    "# encoder = Encoder(in_dim, hidden_dims, latent_dim) for testing\n",
    "# decoder = Decoder(latent_dim, hidden_dims) for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded.shape: torch.Size([6, 128, 3, 3])\n",
      "encoded.shape after flatten: torch.Size([6, 1152])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 6.2127e-01,  4.3679e-01, -4.9945e-01,  ...,  8.9123e-01,\n",
       "             6.2095e-01, -1.6943e-01],\n",
       "           [-9.7679e-01, -2.5637e-01,  2.3110e-01,  ...,  1.8704e-01,\n",
       "            -2.1503e-01, -4.8144e-01],\n",
       "           [-5.5388e-01, -7.7562e-01, -5.7911e-01,  ...,  3.5442e-01,\n",
       "            -5.2527e-02, -2.8206e-01],\n",
       "           ...,\n",
       "           [ 6.9180e-01, -1.6230e-02, -1.3026e-01,  ...,  7.1330e-01,\n",
       "            -1.6798e-01,  5.3718e-02],\n",
       "           [-2.5497e-01, -4.2844e-01, -8.0627e-01,  ...,  2.2175e-01,\n",
       "            -4.0637e-01, -5.3341e-02],\n",
       "           [-1.1091e-01,  1.4218e-02, -1.7719e-01,  ..., -3.7198e-01,\n",
       "             6.8662e-01, -1.2087e-01]],\n",
       " \n",
       "          [[-7.3256e-01, -9.6734e-01, -8.7966e-01,  ...,  5.1233e-01,\n",
       "            -1.3779e-02,  1.2253e-01],\n",
       "           [-8.6216e-02, -8.1402e-01,  8.7467e-01,  ..., -7.8543e-01,\n",
       "             8.2743e-01,  1.4651e-01],\n",
       "           [-3.3732e-01, -6.4741e-01, -5.7643e-01,  ..., -2.0220e-01,\n",
       "             1.5155e-01, -1.9310e-01],\n",
       "           ...,\n",
       "           [ 4.5556e-01,  8.2438e-01,  8.6029e-01,  ...,  3.7324e-01,\n",
       "            -3.9676e-01,  1.5691e-01],\n",
       "           [-8.5629e-03,  1.5020e-01, -7.9468e-01,  ...,  1.5056e-01,\n",
       "             1.6329e-01,  4.1501e-01],\n",
       "           [ 1.8010e-01, -6.4982e-01, -3.7017e-01,  ...,  2.7786e-01,\n",
       "             7.3177e-02, -3.3694e-01]],\n",
       " \n",
       "          [[ 6.9624e-01, -5.7092e-02,  2.6327e-01,  ..., -8.7907e-02,\n",
       "             1.8336e-01, -3.3316e-01],\n",
       "           [ 1.6968e-01,  8.1660e-01,  4.1447e-01,  ..., -5.3705e-01,\n",
       "            -5.4535e-01,  4.8376e-01],\n",
       "           [ 1.6012e-01, -8.1339e-01, -6.7484e-01,  ...,  4.9098e-01,\n",
       "            -2.2434e-01,  4.8131e-01],\n",
       "           ...,\n",
       "           [-1.2087e-01,  1.5903e-01, -3.8599e-01,  ...,  3.3640e-01,\n",
       "             2.7187e-01, -7.0460e-01],\n",
       "           [ 4.3210e-01,  6.7382e-01, -6.1583e-01,  ...,  1.6988e-02,\n",
       "            -7.6212e-01,  5.8240e-01],\n",
       "           [ 1.6875e-01,  2.4593e-01,  3.4279e-01,  ..., -2.5648e-01,\n",
       "             5.0365e-01,  5.8361e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.9690e-02,  4.8846e-02, -2.0056e-01,  ...,  1.9068e-02,\n",
       "            -7.0732e-01,  3.2048e-01],\n",
       "           [ 5.5295e-01, -2.1745e-01,  7.5468e-01,  ..., -4.4688e-01,\n",
       "            -4.9183e-01, -5.2468e-01],\n",
       "           [ 3.1704e-02,  5.0078e-01,  9.6691e-02,  ..., -9.2453e-01,\n",
       "            -5.2451e-01,  6.6455e-01],\n",
       "           ...,\n",
       "           [-4.2742e-01, -5.6631e-01, -9.6667e-01,  ..., -4.5460e-01,\n",
       "             2.8711e-01, -3.1387e-01],\n",
       "           [ 5.5694e-01,  8.2017e-01,  4.9688e-01,  ...,  2.5678e-01,\n",
       "             5.8655e-01, -1.3132e-01],\n",
       "           [-3.9678e-01,  4.7527e-01, -7.8881e-01,  ..., -4.7544e-01,\n",
       "            -1.0376e-01,  1.1047e-01]],\n",
       " \n",
       "          [[ 2.4089e-01, -7.2491e-01, -4.8133e-01,  ...,  3.6182e-01,\n",
       "             3.4769e-01,  2.3516e-01],\n",
       "           [-1.6225e-01, -9.9476e-01,  5.3004e-01,  ...,  8.6883e-01,\n",
       "            -7.3570e-01, -3.7758e-01],\n",
       "           [-8.1074e-01,  8.0047e-01, -4.4109e-01,  ..., -5.1697e-01,\n",
       "            -2.7331e-01,  6.1970e-01],\n",
       "           ...,\n",
       "           [ 4.1389e-01, -5.1608e-01, -7.9594e-01,  ..., -3.9552e-03,\n",
       "            -2.0307e-01, -4.3359e-01],\n",
       "           [ 1.3541e-02, -6.2924e-01, -8.9946e-01,  ...,  1.5567e-01,\n",
       "            -1.2464e-01, -1.1241e-01],\n",
       "           [-2.4802e-01, -7.4327e-02,  2.8243e-01,  ..., -4.2109e-01,\n",
       "            -1.4625e-01, -5.8919e-02]],\n",
       " \n",
       "          [[ 8.1468e-02,  7.2093e-01,  2.7679e-01,  ..., -2.6819e-02,\n",
       "            -1.6455e-01,  2.0908e-01],\n",
       "           [ 8.5364e-01,  5.5733e-01, -2.3381e-01,  ..., -7.2577e-01,\n",
       "             4.5317e-01, -9.0508e-01],\n",
       "           [ 3.0916e-03,  6.2444e-01, -6.9941e-02,  ..., -8.9560e-01,\n",
       "             5.0843e-01,  7.5008e-01],\n",
       "           ...,\n",
       "           [-6.6686e-01, -1.7266e-01, -2.1833e-01,  ..., -1.6735e-02,\n",
       "             6.7937e-01,  1.8347e-01],\n",
       "           [ 5.5765e-01,  6.8587e-02,  4.8769e-01,  ...,  7.8997e-01,\n",
       "            -7.6765e-02,  8.7493e-02],\n",
       "           [ 1.2471e-01,  5.8326e-01, -1.8532e-03,  ..., -3.0641e-02,\n",
       "            -5.2978e-01,  7.4514e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.1064e-01, -3.0374e-01,  3.8659e-01,  ...,  6.0912e-01,\n",
       "            -5.5972e-01,  6.0771e-01],\n",
       "           [-3.0888e-01,  5.9993e-01,  7.9414e-01,  ...,  8.9545e-01,\n",
       "            -2.4395e-01,  4.0770e-01],\n",
       "           [ 3.9020e-01,  8.0755e-01, -4.2350e-01,  ...,  9.0935e-03,\n",
       "            -1.1566e-01, -7.4507e-02],\n",
       "           ...,\n",
       "           [ 6.4905e-01, -1.9129e-01, -3.8381e-01,  ...,  2.4228e-02,\n",
       "            -5.8990e-01, -4.0030e-01],\n",
       "           [-8.6705e-02,  6.3094e-01,  7.4388e-02,  ..., -7.3380e-01,\n",
       "            -1.6794e-01, -1.5778e-01],\n",
       "           [ 2.2353e-01, -7.6636e-01,  8.6013e-01,  ..., -5.3284e-02,\n",
       "             8.5694e-02, -5.2642e-02]],\n",
       " \n",
       "          [[-3.2287e-01, -4.6585e-01, -2.6465e-01,  ..., -4.3899e-01,\n",
       "             8.7317e-02,  2.8236e-01],\n",
       "           [-6.3715e-01,  6.1397e-01, -3.9700e-01,  ...,  4.7417e-01,\n",
       "            -3.3742e-01, -7.6056e-01],\n",
       "           [-5.4732e-01,  2.2960e-01, -2.8522e-01,  ..., -6.5853e-01,\n",
       "            -1.5487e-01, -8.5821e-01],\n",
       "           ...,\n",
       "           [ 3.3837e-02,  4.5189e-01,  6.3019e-01,  ..., -5.2396e-01,\n",
       "            -5.3599e-01, -9.7895e-02],\n",
       "           [ 1.5408e-01,  7.0769e-01, -3.2440e-01,  ...,  3.4370e-01,\n",
       "             4.5235e-01,  4.4546e-02],\n",
       "           [ 4.2528e-03,  4.9366e-01,  6.8226e-01,  ..., -6.1890e-01,\n",
       "            -4.8535e-01, -1.6992e-02]],\n",
       " \n",
       "          [[-2.6022e-01, -4.7490e-01, -1.0646e-01,  ..., -1.9917e-01,\n",
       "             1.7404e-02,  1.3258e-01],\n",
       "           [ 5.1567e-01,  3.4761e-01, -3.2403e-01,  ...,  5.3462e-01,\n",
       "            -1.7690e-01,  3.0515e-01],\n",
       "           [ 2.8141e-01,  3.9563e-01, -3.9536e-01,  ..., -2.9978e-01,\n",
       "             4.6137e-01, -7.0661e-01],\n",
       "           ...,\n",
       "           [ 6.8307e-01,  3.0525e-01, -1.7605e-01,  ..., -4.9209e-01,\n",
       "             3.9845e-01,  3.7747e-01],\n",
       "           [ 1.0926e-01,  5.2171e-01,  6.9946e-01,  ...,  6.9796e-01,\n",
       "             6.1481e-01, -1.9947e-01],\n",
       "           [-5.4655e-01, -5.1847e-01, -2.9130e-02,  ...,  1.3570e-01,\n",
       "            -6.7117e-02, -1.4757e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.5526e-01,  6.9955e-01, -2.5504e-01,  ...,  4.2536e-01,\n",
       "             2.1011e-02,  1.0862e-01],\n",
       "           [ 2.0086e-01,  5.8110e-01,  5.4600e-01,  ...,  1.6091e-01,\n",
       "             1.4787e-01,  2.5720e-01],\n",
       "           [-8.5624e-02,  8.8109e-01,  5.1694e-01,  ..., -1.2050e-03,\n",
       "            -8.6324e-02,  8.6515e-01],\n",
       "           ...,\n",
       "           [ 2.6041e-01,  2.8697e-01, -9.2948e-01,  ..., -5.3154e-01,\n",
       "             2.0192e-01, -6.4050e-01],\n",
       "           [ 4.6352e-01,  3.1079e-01, -2.0457e-01,  ...,  1.7034e-01,\n",
       "             7.6991e-01, -4.8250e-01],\n",
       "           [ 2.3957e-01, -4.4285e-02, -4.1654e-01,  ...,  2.0593e-01,\n",
       "            -1.2107e-01, -4.2449e-01]],\n",
       " \n",
       "          [[ 7.1527e-02,  8.3882e-03,  4.5576e-03,  ...,  3.0175e-01,\n",
       "            -3.6886e-01, -1.1910e-01],\n",
       "           [ 4.4038e-01,  8.7641e-01, -6.1345e-01,  ..., -3.7065e-01,\n",
       "            -2.1964e-01,  2.7540e-01],\n",
       "           [-9.4276e-02, -9.2485e-01,  6.8291e-01,  ..., -6.3075e-01,\n",
       "            -2.8046e-04,  7.4371e-01],\n",
       "           ...,\n",
       "           [ 3.7354e-01, -2.2047e-01, -6.3303e-01,  ...,  6.2665e-02,\n",
       "             4.3827e-02,  1.3788e-02],\n",
       "           [-2.1879e-01,  2.6354e-01, -3.7854e-01,  ..., -3.6148e-01,\n",
       "             6.4357e-01, -6.5724e-01],\n",
       "           [-3.2841e-01,  3.3561e-01,  8.6567e-02,  ..., -3.9486e-01,\n",
       "             6.5459e-01,  2.4599e-01]],\n",
       " \n",
       "          [[-3.7545e-01,  2.6362e-01,  1.0521e-01,  ...,  3.0821e-01,\n",
       "             3.2006e-01,  4.1195e-01],\n",
       "           [ 7.7549e-01, -1.7302e-01,  1.4003e-01,  ..., -5.2447e-01,\n",
       "             7.6740e-01, -9.5965e-01],\n",
       "           [-3.2601e-01,  1.7131e-01, -3.4612e-01,  ...,  6.5747e-01,\n",
       "             1.9420e-01,  6.2383e-01],\n",
       "           ...,\n",
       "           [ 4.1973e-02,  8.7473e-01, -8.8810e-02,  ..., -1.4885e-01,\n",
       "             6.4797e-01,  1.6363e-01],\n",
       "           [ 5.3601e-02, -5.7529e-01, -1.7502e-01,  ...,  5.7755e-02,\n",
       "             4.9617e-01, -4.0457e-01],\n",
       "           [ 3.7628e-01,  1.2906e-01, -9.8411e-03,  ..., -1.2584e-01,\n",
       "            -2.1081e-01, -1.7263e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.0487e-02,  5.7753e-01,  2.5112e-01,  ..., -3.7852e-01,\n",
       "            -7.6252e-01, -1.4237e-01],\n",
       "           [-7.7647e-01,  9.1072e-01, -8.0345e-01,  ..., -6.9007e-01,\n",
       "             4.9321e-01,  6.8882e-01],\n",
       "           [-3.9868e-01, -2.4279e-01, -5.8439e-01,  ..., -8.2457e-01,\n",
       "             6.5949e-01,  8.9364e-01],\n",
       "           ...,\n",
       "           [-9.9435e-02, -7.9349e-01, -7.6523e-01,  ...,  7.7532e-02,\n",
       "            -7.5759e-01, -2.0129e-01],\n",
       "           [-2.6698e-01,  6.8404e-01,  3.5578e-01,  ...,  6.3753e-02,\n",
       "             7.5678e-01, -2.1457e-01],\n",
       "           [-3.3846e-01,  5.0361e-01,  7.7272e-01,  ..., -7.0859e-01,\n",
       "            -6.9535e-01,  1.6633e-01]],\n",
       " \n",
       "          [[ 3.5726e-01,  7.6630e-01,  6.2115e-01,  ...,  4.7689e-02,\n",
       "            -6.0112e-01,  9.8494e-02],\n",
       "           [ 9.3208e-01,  7.2355e-01,  1.4849e-01,  ...,  6.4820e-01,\n",
       "            -9.6323e-01, -2.5520e-01],\n",
       "           [-9.0160e-01, -2.8388e-03, -1.4940e-01,  ...,  3.5746e-01,\n",
       "             4.1341e-01,  9.7224e-01],\n",
       "           ...,\n",
       "           [-1.4185e-01, -9.5538e-01, -4.5456e-01,  ..., -9.3401e-01,\n",
       "            -8.5889e-01,  3.2590e-02],\n",
       "           [-5.6836e-01, -3.1741e-01, -2.8292e-01,  ..., -3.3718e-01,\n",
       "             1.0907e-01, -5.6141e-01],\n",
       "           [-5.0424e-01,  4.4034e-01,  5.0055e-01,  ..., -1.8067e-02,\n",
       "            -5.8295e-02,  2.8112e-01]],\n",
       " \n",
       "          [[-4.8609e-01,  2.0280e-02,  4.6517e-01,  ...,  2.8752e-01,\n",
       "             3.6625e-01,  3.3655e-01],\n",
       "           [-9.1086e-01,  9.1534e-01, -3.3250e-01,  ..., -5.7770e-01,\n",
       "             8.5579e-01, -6.6761e-01],\n",
       "           [ 5.7659e-01,  3.7538e-01, -9.7022e-01,  ..., -6.4918e-01,\n",
       "             6.0630e-01,  7.7938e-01],\n",
       "           ...,\n",
       "           [ 4.4748e-01,  5.6552e-01, -6.8373e-01,  ..., -3.8545e-02,\n",
       "            -4.3474e-01,  2.4519e-01],\n",
       "           [ 5.3188e-01, -4.3184e-02,  1.9551e-01,  ...,  5.8172e-01,\n",
       "             8.3949e-01, -4.9556e-01],\n",
       "           [ 1.6826e-01,  4.4692e-01,  8.0946e-01,  ..., -4.8679e-01,\n",
       "            -1.9169e-01, -3.9200e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.3234e-02, -5.8406e-01,  9.0090e-01,  ...,  3.5894e-01,\n",
       "             3.2177e-01, -1.2957e-01],\n",
       "           [-7.6081e-01,  9.2450e-01,  1.2285e-01,  ...,  2.7551e-01,\n",
       "            -5.9495e-01,  3.4655e-01],\n",
       "           [-3.8114e-01, -7.2476e-01,  7.4625e-01,  ..., -7.4757e-01,\n",
       "            -4.3119e-01,  5.7130e-01],\n",
       "           ...,\n",
       "           [ 8.9924e-01,  4.0666e-01, -5.6070e-01,  ...,  7.4050e-01,\n",
       "            -5.7258e-01, -9.6917e-02],\n",
       "           [ 6.1731e-01,  7.1191e-01, -4.4725e-01,  ...,  1.5163e-01,\n",
       "            -3.4034e-01, -4.9553e-01],\n",
       "           [-7.2228e-02, -2.5502e-01,  3.9088e-01,  ..., -7.2053e-01,\n",
       "            -7.0187e-02,  9.0758e-02]],\n",
       " \n",
       "          [[-4.8300e-01, -4.7804e-01,  3.3514e-01,  ...,  4.9726e-01,\n",
       "            -1.8913e-01,  3.1229e-02],\n",
       "           [-9.4976e-02, -3.2757e-01,  6.0339e-01,  ..., -1.9457e-01,\n",
       "            -1.7548e-02,  3.2985e-01],\n",
       "           [-8.4260e-01, -2.0531e-01,  9.1947e-01,  ...,  6.9163e-02,\n",
       "            -9.3748e-01,  7.2212e-01],\n",
       "           ...,\n",
       "           [ 5.8919e-01,  7.2603e-01,  8.3703e-01,  ..., -8.7776e-01,\n",
       "             4.2578e-02, -1.6620e-01],\n",
       "           [ 2.9985e-01,  5.3842e-01, -7.5076e-01,  ...,  2.8536e-01,\n",
       "             2.2620e-01, -4.4726e-01],\n",
       "           [-1.0563e-01,  4.9180e-01,  2.4792e-01,  ..., -1.8200e-01,\n",
       "            -3.2731e-02,  8.0646e-02]],\n",
       " \n",
       "          [[ 5.0607e-01, -5.4022e-01,  4.9736e-02,  ...,  1.4265e-01,\n",
       "             6.0247e-01,  1.6233e-01],\n",
       "           [ 4.3128e-01,  9.1450e-01, -6.0198e-01,  ..., -8.0415e-02,\n",
       "             8.3725e-01, -7.8040e-01],\n",
       "           [-4.1639e-01, -3.7521e-01, -1.8928e-01,  ...,  4.3802e-01,\n",
       "            -6.2874e-01,  4.5125e-01],\n",
       "           ...,\n",
       "           [ 9.7194e-02,  5.8055e-01, -9.5791e-01,  ...,  4.5837e-01,\n",
       "            -4.9190e-01,  4.8240e-01],\n",
       "           [-8.8329e-02,  1.9791e-01, -3.7200e-01,  ...,  2.2928e-01,\n",
       "             2.9208e-01, -1.3615e-01],\n",
       "           [ 2.7541e-01, -2.1042e-01,  2.3849e-01,  ..., -5.2758e-01,\n",
       "            -3.3585e-01, -6.9609e-03]]]], grad_fn=<TanhBackward0>),\n",
       " tensor([[ 6.1290e-01, -2.1193e-01, -2.9864e-01, -6.2982e-01, -1.3825e-01,\n",
       "           4.7328e-01,  5.6297e-02,  1.0469e+00, -6.8340e-01, -9.1157e-01,\n",
       "           9.5482e-02,  7.0684e-02, -1.3065e-01, -5.4630e-01, -2.0233e-03,\n",
       "          -2.2836e-01,  8.7908e-01,  3.6765e-02, -3.0909e-02, -2.3172e-01,\n",
       "          -4.3885e-01, -1.0716e-01, -9.4042e-02, -1.1472e-01, -3.4680e-01,\n",
       "          -1.3741e-01, -5.6171e-01,  4.7914e-01, -6.0330e-02, -3.4164e-01,\n",
       "          -7.8819e-02,  4.1307e-01, -9.5021e-04, -2.8014e-02, -9.0807e-01,\n",
       "           1.9036e-01,  8.1827e-01, -4.7602e-01,  2.9538e-01, -1.0488e-01,\n",
       "          -3.1563e-01,  7.2519e-01,  5.0721e-01,  2.3360e-01, -2.8356e-01,\n",
       "           3.9964e-01, -3.7052e-02, -4.1102e-01, -2.0399e-01, -1.8263e-01,\n",
       "           8.4926e-02, -1.0960e+00, -1.1794e-01,  4.2945e-01, -5.2514e-01,\n",
       "          -5.0126e-01,  7.2502e-01, -5.2758e-01, -4.5706e-01,  9.0674e-02,\n",
       "          -3.7607e-01,  1.6693e-01, -2.3426e-01,  7.3409e-01],\n",
       "         [ 3.0883e-01, -2.1332e-01, -4.9106e-01, -4.0491e-01, -4.1993e-01,\n",
       "          -4.3938e-02, -2.3177e-01, -2.4110e-01,  6.4867e-01, -3.3081e-02,\n",
       "          -1.9670e-02, -1.9030e-01, -1.3783e-01, -3.3481e-01, -2.4245e-01,\n",
       "           2.8195e-01,  7.4610e-01, -6.1544e-01,  3.4473e-02, -6.5373e-02,\n",
       "          -6.7341e-01, -9.9075e-02,  1.5069e-01, -1.5265e-01,  3.9674e-01,\n",
       "          -8.4682e-02, -3.1191e-01, -4.6844e-02, -7.2653e-02, -4.3108e-01,\n",
       "          -1.2409e-01,  1.3673e-01, -3.3201e-01, -2.0611e-03, -5.2557e-02,\n",
       "           3.4291e-01,  4.7781e-02, -1.3451e-01,  2.1504e-01, -2.2673e-02,\n",
       "          -3.1910e-02, -1.6760e-01, -8.0349e-02,  3.6813e-01, -3.5925e-01,\n",
       "           2.4065e-01, -9.1134e-02, -4.9423e-01, -2.5877e-01, -7.3080e-02,\n",
       "          -3.9165e-01, -7.7393e-02, -3.7434e-02,  2.5390e-01, -8.7962e-02,\n",
       "          -1.8712e-02,  3.6484e-01,  1.2879e-01, -2.6853e-01,  1.6522e-01,\n",
       "           3.3136e-02,  1.1716e-01, -2.4655e-01,  4.7493e-01],\n",
       "         [ 3.5876e-01, -4.2288e-02,  2.8845e-01, -3.6024e-01, -1.7999e-01,\n",
       "           3.1218e-01,  1.4638e-01, -7.1189e-01,  2.2625e-03,  9.1080e-03,\n",
       "          -5.8809e-01, -2.8931e-01, -1.7324e-01, -3.7333e-01,  3.6609e-02,\n",
       "          -3.6020e-01,  3.3865e-01,  4.8283e-02,  4.5265e-01, -3.1174e-01,\n",
       "          -3.7970e-01, -1.4908e-01, -3.1758e-01,  2.7502e-01,  6.8126e-02,\n",
       "          -3.0470e-01, -1.0583e-01,  3.9582e-01, -3.6219e-01, -2.9055e-03,\n",
       "           2.0236e-01,  6.4167e-01,  6.0049e-02, -2.7520e-01, -4.4712e-01,\n",
       "           6.2519e-03,  6.2003e-02, -4.5952e-01,  3.2577e-01, -1.1107e-01,\n",
       "          -5.2113e-01, -1.3242e-01, -9.4075e-02, -1.0446e-01, -3.5720e-01,\n",
       "           2.2249e-01,  1.3689e-01, -2.4794e-01, -2.2061e-01, -2.6245e-01,\n",
       "          -1.3818e-01, -3.7831e-01, -3.4576e-03,  4.5870e-01,  1.2014e-01,\n",
       "          -3.0112e-02,  1.7005e-01, -2.6891e-01, -1.5022e-01,  4.4971e-01,\n",
       "           2.2700e-02,  3.6663e-01,  7.0502e-02,  2.5936e-01],\n",
       "         [ 4.4239e-01, -3.4958e-01,  1.3605e-01, -7.7915e-01,  1.2486e-01,\n",
       "          -2.2033e-01, -3.2063e-01, -3.8933e-01,  1.8606e-01,  4.4527e-01,\n",
       "          -1.8212e-01, -1.9758e-01,  2.1738e-02, -6.2397e-01, -3.4552e-01,\n",
       "          -2.5761e-01,  4.2742e-01,  4.6856e-01, -2.0557e-02, -1.0004e-01,\n",
       "          -1.6082e-01, -4.2827e-01, -8.5109e-02,  3.4031e-01,  3.7478e-03,\n",
       "          -1.6076e-01,  7.5311e-02, -1.7433e-01,  5.7541e-02, -4.5341e-01,\n",
       "          -3.2985e-01, -2.7397e-01, -3.7219e-01, -1.6385e-02,  1.3468e-01,\n",
       "          -4.8564e-01,  6.9381e-01,  1.4735e-01,  3.7643e-01, -6.4188e-01,\n",
       "          -5.5704e-01,  7.9345e-02,  1.6512e-01,  4.3803e-01, -2.9198e-01,\n",
       "          -3.0933e-01,  4.0604e-01, -1.0932e+00, -4.5421e-01, -2.3735e-01,\n",
       "           6.1780e-02, -8.5152e-01,  1.7987e-01,  2.9241e-01, -2.9021e-01,\n",
       "          -1.6020e-02,  7.0199e-01, -6.3567e-01,  3.1230e-01, -9.2959e-02,\n",
       "          -1.1033e-01, -1.8755e-01,  6.0586e-02, -1.2840e-01],\n",
       "         [-2.8815e-01,  3.6865e-02, -2.6502e-01, -1.2877e+00,  1.0224e-01,\n",
       "          -1.9945e-01,  2.5194e-01,  5.7408e-02,  3.6142e-01,  3.5217e-01,\n",
       "           5.6704e-01,  5.9427e-01, -3.7558e-01, -1.1299e+00, -5.5991e-01,\n",
       "          -4.3129e-02, -2.4222e-02, -9.4531e-02,  4.0869e-01, -2.8507e-01,\n",
       "          -5.8902e-01, -7.4354e-01,  4.2870e-01,  3.6096e-01,  1.6942e-02,\n",
       "          -4.7456e-01, -4.4794e-01,  1.8354e-01, -3.1009e-01, -4.5865e-02,\n",
       "           2.0421e-01,  3.2968e-01, -1.1477e-01, -1.1614e+00, -6.3051e-01,\n",
       "          -2.0568e-01, -4.1465e-01, -3.9317e-01, -3.6324e-01,  5.4334e-01,\n",
       "          -2.0728e-01,  4.2922e-01, -5.9379e-02,  8.8091e-01, -1.2519e-01,\n",
       "          -4.1145e-01,  2.1602e-01, -1.4630e-01,  5.6770e-01,  7.8348e-02,\n",
       "           2.8664e-01, -5.4403e-01,  2.0942e-01,  4.5826e-01, -1.1568e+00,\n",
       "          -1.7833e-01,  4.9607e-02,  5.0752e-01, -7.5318e-01,  2.4689e-01,\n",
       "           2.4147e-01, -4.7711e-01,  1.4919e-01,  6.5977e-01],\n",
       "         [ 8.5578e-02, -3.4548e-01, -1.8839e-01, -7.5489e-01, -2.9813e-01,\n",
       "          -1.5087e-01, -4.9074e-01, -8.6423e-01,  4.6834e-01,  3.7117e-01,\n",
       "           8.8783e-02,  9.8394e-02, -1.9252e-01, -3.4676e-01, -3.5701e-01,\n",
       "          -2.3403e-01,  5.4567e-01, -1.1180e-01, -4.0852e-02, -8.8490e-01,\n",
       "          -6.1224e-01, -6.6075e-02, -8.1026e-01,  5.3080e-01,  7.0243e-01,\n",
       "          -8.2737e-01, -6.1145e-01, -4.4719e-02, -4.8954e-01, -4.0215e-01,\n",
       "           5.5017e-01, -2.6011e-01,  2.3415e-02, -1.4289e-01, -1.4030e-01,\n",
       "          -2.9766e-01,  2.2245e-01, -5.4782e-01, -3.9677e-01,  1.6824e-01,\n",
       "           2.2831e-01, -7.7867e-02, -5.1117e-01, -3.8704e-01, -1.1070e+00,\n",
       "          -3.2016e-01, -9.1614e-02,  1.6115e-01,  1.5702e-01, -8.5932e-01,\n",
       "          -7.1653e-01, -8.0635e-01, -2.0067e-01,  4.9969e-01, -9.2563e-01,\n",
       "          -8.5287e-02,  3.8715e-01,  6.1496e-02, -3.0983e-02,  1.4411e-01,\n",
       "          -3.0423e-01, -9.6689e-02,  7.5189e-01,  3.2327e-01]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.3612, -0.2312,  0.3211,  0.1591,  0.0200, -0.1393, -0.0412,  0.0954,\n",
       "           0.0902,  0.2924,  0.0275, -0.2767, -0.5709,  0.2752,  0.5346, -0.1871,\n",
       "           0.3429,  0.2572, -0.1796, -0.3039,  0.1797,  0.3749, -0.0307,  0.0671,\n",
       "           0.6523, -0.4352,  0.3937, -1.2790, -0.0473,  0.1456,  0.0681,  0.4696,\n",
       "           1.0160, -0.5366, -0.5160,  0.6227,  0.7206,  0.5837, -0.2426,  0.3983,\n",
       "           0.1032, -0.8503,  0.3317,  0.3502,  0.3953, -0.1907,  0.4862, -0.5650,\n",
       "           0.2081, -0.1268,  0.2702,  0.0927, -0.0018, -0.5296, -0.5512, -0.3495,\n",
       "           0.4904, -0.4720,  0.1633, -0.3029, -0.3245,  0.2057,  1.3169,  0.5889],\n",
       "         [ 0.2121, -0.1820, -0.3082,  0.2878,  0.3684,  0.1597, -0.3704, -0.0410,\n",
       "           0.2258,  0.4349, -0.0981,  0.3699, -0.4929,  0.0950,  0.3798, -0.5056,\n",
       "           0.2042,  0.3830, -0.1646, -0.3358,  0.1576,  0.1062,  0.2713, -0.1560,\n",
       "           0.2639, -0.5001, -0.1587, -0.5472, -0.0345,  0.0824,  0.0262,  0.4077,\n",
       "           0.3493,  0.1417, -0.2308,  0.5894,  0.2026,  0.0945, -0.0668, -0.0861,\n",
       "          -0.0346, -0.3679,  0.1576, -0.1198,  0.0466, -0.0235,  0.3640,  0.0413,\n",
       "           0.2951,  0.1595,  0.1124, -0.4068, -0.0190, -0.1466, -0.1582,  0.0273,\n",
       "           0.4221, -0.0398,  0.0417,  0.0757,  0.1899,  0.0418,  0.4055,  0.2394],\n",
       "         [-0.6748, -0.3896,  0.3061,  0.0203,  0.0710, -0.3751, -0.4662,  0.0536,\n",
       "          -0.1044,  0.3873, -0.3204,  0.4814,  0.0655,  0.6771, -0.2873, -0.3415,\n",
       "           0.3563,  0.6178, -0.9528, -0.0370,  0.2188,  0.6533, -0.1075, -0.3248,\n",
       "           0.0754,  0.2740,  0.5327, -0.3451, -0.1406, -0.0887,  0.2575,  0.2922,\n",
       "           0.2247,  0.0905, -0.2342,  0.5089, -0.2003, -0.0518, -0.5090, -0.5401,\n",
       "           0.2061,  0.1489, -0.0641,  0.1210, -0.2520, -0.0220,  0.3794, -0.2744,\n",
       "          -0.1774,  0.0804,  0.0610,  0.0023, -0.4581, -0.9765,  0.0657, -0.2907,\n",
       "           0.3323, -0.4592,  0.0406, -0.1257,  0.1372, -0.3748,  0.7407, -0.0209],\n",
       "         [-0.3192, -0.8162,  0.2321,  0.5930, -0.0728, -0.5287,  0.1596, -0.3924,\n",
       "           0.0139,  0.3241,  0.0647,  0.5148, -0.5134,  0.3118,  0.0487,  0.1003,\n",
       "           0.0882, -0.1264,  0.1166, -0.5104, -0.1186,  0.1830,  0.6997, -0.1534,\n",
       "          -0.2004,  0.0899,  0.2762, -0.6903, -0.0688, -0.4609,  0.3190,  0.0487,\n",
       "          -0.0497,  0.1661,  0.0061,  0.8920, -0.2914, -0.0334, -0.0536,  0.3429,\n",
       "           0.6100, -0.3084, -0.3382,  0.4803, -0.2320,  0.0087,  0.0128, -0.2653,\n",
       "           0.1844,  0.1539,  0.2347, -0.6123,  0.2161, -0.6937, -0.0156, -0.5627,\n",
       "           0.8514, -0.4221,  0.2885, -0.2438, -0.0420, -0.1526,  0.0079,  0.1336],\n",
       "         [-0.4963, -0.8130, -0.1505,  0.1962,  0.0593,  0.2539, -0.0654,  0.0076,\n",
       "          -0.8040, -0.0438,  0.1306,  1.7650, -0.5772,  0.7599, -0.1261, -0.1597,\n",
       "           0.5328,  0.3134,  0.2172,  0.6487, -0.7981,  0.5332,  0.0285,  0.7236,\n",
       "          -0.2552, -0.3376,  0.0553, -0.1200, -0.4646, -0.4434,  0.9184,  0.3924,\n",
       "          -0.2318,  0.6421, -0.0524,  0.3458, -0.0031,  0.0427, -1.2240,  0.8003,\n",
       "           0.6348, -0.0545,  0.1096, -0.1734,  0.3733,  0.1929,  0.0126, -0.4432,\n",
       "          -0.2810,  0.5480,  0.5953,  0.4178, -0.1423, -0.5919, -0.0402, -0.6638,\n",
       "           0.8554, -0.1718, -0.1690,  0.4179,  0.2396,  0.1160,  0.2639,  0.8640],\n",
       "         [-0.0886, -0.6508, -0.4814,  0.9588, -0.1306, -0.3993, -0.1202, -0.1287,\n",
       "          -0.9920, -0.1554, -0.4785,  0.2843, -0.5886, -0.1725, -0.1810,  0.2115,\n",
       "          -0.2117,  0.3092,  0.2236,  0.2632, -0.5861,  0.7156,  0.4274,  0.9304,\n",
       "           0.3813, -0.6661, -0.0768, -0.4557,  0.1317, -0.3871,  0.3791,  0.1936,\n",
       "           0.4724,  0.0877, -0.9137,  0.2437,  0.1547,  0.5950,  0.1291,  0.5543,\n",
       "           0.4353,  0.2908, -0.0265,  0.2890, -0.7158, -0.1777, -0.6036, -0.3540,\n",
       "           0.2339, -0.0293,  0.7131,  0.0777, -0.0637, -0.7229, -0.3121,  0.0427,\n",
       "           1.0961, -0.4646,  0.9499,  0.5675,  0.5117, -0.7124,  0.3416,  0.8248]],\n",
       "        grad_fn=<AddmmBackward0>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Testing the model\n",
    "model.forward(training_tensor)\n",
    "\n",
    "# # Code to test out the encoder & decoder\n",
    "# mu, log_var = encoder.forward(training_tensor)\n",
    "# print(\"mu: \", mu.shape)\n",
    "# print(\"log_var: \", log_var.shape)\n",
    "\n",
    "# reconstructed_img = decoder.forward(mu, log_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(reconstructed_img, input_img, mu, log_var, kld_weight=2):\n",
    "    print(\"reconstructed_img: \", reconstructed_img.shape)\n",
    "    print(\"input_img: \", input_img.shape)\n",
    "    img_loss = F.mse_loss(reconstructed_img, input_img)\n",
    "    # article on calculating kl divergence between 2 gaussians:\n",
    "    # https://medium.com/@outerrencedl/variational-autoencoder-and-a-bit-kl-divergence-with-pytorch-ce04fd55d0d7\n",
    "    kld_loss = torch.mean(\n",
    "        torch.sum(-log_var + (log_var.exp() ** 2 + mu**2) / 2 - 1 / 2)\n",
    "    )\n",
    "    kld_loss *= kld_weight\n",
    "\n",
    "    return img_loss + kld_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(model, loss_func, x, y, xvalid, yvalid, lr=0.1, steps=5000):\n",
    "    # only really need x or y, they are the same thing\n",
    "    optimizer = optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "    losses = []\n",
    "    valid_losses = []\n",
    "    for _ in tqdm.trange(steps):\n",
    "        model.train()\n",
    "        reconstructed_img, mu, log_var = model(x)\n",
    "        # y is the original image I think?\n",
    "        loss = loss_func(reconstructed_img, y, mu, log_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        reconstructed_img, mu, log_var = model(xvalid)\n",
    "        valid_loss = loss_func(reconstructed_img, yvalid, mu, log_var)\n",
    "        losses.append(loss.detach().numpy())\n",
    "        valid_losses.append(valid_loss.detach().numpy())\n",
    "\n",
    "    print(f\"Final training loss: {losses[-1]}\")\n",
    "\n",
    "    return losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded.shape: torch.Size([6, 128, 3, 3])\n",
      "encoded.shape after flatten: torch.Size([6, 1152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j3/ll6yjvb96yjb1gn7mk4x45zh0000gn/T/ipykernel_59731/241648366.py:4: UserWarning: Using a target size (torch.Size([6, 3, 64, 64])) that is different to the input size (torch.Size([6, 3, 8, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  img_loss = F.mse_loss(reconstructed_img, input_img)\n",
      "  0%|          | 0/5000 [06:13<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_img:  torch.Size([6, 3, 8, 8])\n",
      "input_img:  torch.Size([6, 3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/davidenders/Desktop/NN/vae-project/training.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m losses, valid_losses \u001b[39m=\u001b[39m gradient_descent(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model, loss_function, training_tensor, training_tensor, cv_tensor, cv_tensor\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/davidenders/Desktop/NN/vae-project/training.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m reconstructed_img, mu, log_var \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# y is the original image I think?\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(reconstructed_img, y, mu, log_var)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m/Users/davidenders/Desktop/NN/vae-project/training.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreconstructed_img: \u001b[39m\u001b[39m\"\u001b[39m, reconstructed_img\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minput_img: \u001b[39m\u001b[39m\"\u001b[39m, input_img\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m img_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmse_loss(reconstructed_img, input_img)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# article on calculating kl divergence between 2 gaussians:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# https://medium.com/@outerrencedl/variational-autoencoder-and-a-bit-kl-divergence-with-pytorch-ce04fd55d0d7\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m kld_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     torch\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39mlog_var \u001b[39m+\u001b[39m (log_var\u001b[39m.\u001b[39mexp() \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m mu\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davidenders/Desktop/NN/vae-project/training.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/NN/lib/python3.11/site-packages/torch/nn/functional.py:3328\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3325\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3326\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3328\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[1;32m   3329\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/Desktop/NN/lib/python3.11/site-packages/torch/functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[0;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (64) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "losses, valid_losses = gradient_descent(\n",
    "    model, loss_function, training_tensor, training_tensor, cv_tensor, cv_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after we've trained, we use the decoder to generate new images\n",
    "# we assume a normal distribution over our latent space\n",
    "# so we sample from that distribution and feed it into the decoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
